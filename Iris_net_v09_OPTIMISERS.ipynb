{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809ed905",
   "metadata": {},
   "source": [
    "## Optimisers example using Iris dataset ##\n",
    "\n",
    "Use this script to experiment with different optimizer settings using the well known Iris dataset\n",
    "\n",
    "Run the first code cell to do all the set up. Then you can try various optimisers (and other settings) in the code cell after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07166265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get dataset\n",
    "#\n",
    "!wget -nv https://github.com/IS-pillar-3/datasets/raw/main/iris.csv\n",
    "#\n",
    "# Libraries\n",
    "#\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#\n",
    "# Data loader class\n",
    "#\n",
    "class IrisDataSet(torch.utils.data.Dataset): \n",
    "    #\n",
    "    def __init__(self, data_path, test_split, vali_split, batch_size):\n",
    "        #\n",
    "        # Store parameters\n",
    "        #\n",
    "        self.test_split = test_split\n",
    "        self.vali_split = test_split\n",
    "        self.batch_size = batch_size\n",
    "        #\n",
    "        # Get the data\n",
    "        #\n",
    "        self.iris_df = pd.read_csv(data_path)\n",
    "        self.iris_df = self.iris_df.sample(frac=1).reset_index(drop=True)\n",
    "        self.no_rows = self.iris_df.shape[0]\n",
    "        #\n",
    "        # Recode the categorical dependent variable\n",
    "        #\n",
    "        le = LabelEncoder()\n",
    "        self.iris_df[\"class\"] = le.fit_transform(self.iris_df[\"class\"])\n",
    "        #\n",
    "        # Split into x and y and store as default train set\n",
    "        #\n",
    "        self.x_train = torch.from_numpy(np.array(self.iris_df.iloc[:, 0:4], dtype=np.float32))\n",
    "        self.y_train = torch.from_numpy(np.array(self.iris_df.iloc[:, 4]))\n",
    "        #\n",
    "        # Free memory\n",
    "        #\n",
    "        self.iris_df = None\n",
    "        #\n",
    "        # Calculate and store split sizes\n",
    "        #\n",
    "        self.test_size = int(np.floor(self.test_split * self.no_rows))\n",
    "        self.vali_size = int(np.floor(self.vali_split * (self.no_rows - self.test_size)))\n",
    "    #\n",
    "    #\n",
    "    def get_test(self):\n",
    "        #\n",
    "        # Splits out a test set\n",
    "        #\n",
    "        idxs = torch.randperm(self.no_rows)\n",
    "        #\n",
    "        x_test = torch.index_select(self.x_train, 0, idxs[0:self.test_size:])\n",
    "        y_test = torch.index_select(self.y_train, 0, idxs[0:self.test_size:])\n",
    "        #\n",
    "        self.x_train = torch.index_select(self.x_train, 0, idxs[self.test_size:])\n",
    "        self.y_train = torch.index_select(self.y_train, 0, idxs[self.test_size:])\n",
    "        #\n",
    "        return x_test, y_test\n",
    "    #\n",
    "    #\n",
    "    def get_vali(self):\n",
    "        #\n",
    "        # Splits out a validation set\n",
    "        #\n",
    "        new_train_size = self.x_train.shape[0] - self.vali_size\n",
    "        #\n",
    "        idxs = torch.randperm(self.x_train.shape[0])\n",
    "        #\n",
    "        x_vali = torch.index_select(self.x_train, 0, idxs[0:self.vali_size])\n",
    "        y_vali = torch.index_select(self.y_train, 0, idxs[0:self.vali_size])\n",
    "        #\n",
    "        self.x_train = torch.index_select(self.x_train, 0, idxs[self.vali_size:])\n",
    "        self.y_train = torch.index_select(self.y_train, 0, idxs[self.vali_size:])\n",
    "        #\n",
    "        return x_vali, y_vali\n",
    "    #\n",
    "    #\n",
    "    def __len__(self):\n",
    "        #\n",
    "        # Rows in dataframe\n",
    "        #\n",
    "        return self.x_train.shape[0]\n",
    "    #\n",
    "    #\n",
    "    def __getitem__(self, batch_idx):\n",
    "        #\n",
    "        # Given a batch_idx return a batch from the training set\n",
    "        #\n",
    "        leng       = self.__len__()\n",
    "        next_item  = batch_idx * self.batch_size % leng\n",
    "        passes     = math.ceil(1 + (self.batch_size - (leng - next_item)) / leng)\n",
    "        remaining  = self.batch_size\n",
    "        #\n",
    "        x = None\n",
    "        y = None\n",
    "        #\n",
    "        for pix in range(passes):\n",
    "            #\n",
    "            last_item = 0\n",
    "            #\n",
    "            while last_item < leng and remaining > 0:\n",
    "                #\n",
    "                last_item  = min(leng, next_item + remaining)\n",
    "                remaining -= last_item - next_item\n",
    "                #\n",
    "                x_ap = self.x_train[next_item:last_item]\n",
    "                y_ap = self.y_train[next_item:last_item]\n",
    "                #\n",
    "                if x is None:\n",
    "                    x = x_ap\n",
    "                    y = y_ap\n",
    "                else:\n",
    "                    x = torch.cat((x, x_ap), axis=0)\n",
    "                    y = torch.cat((y, y_ap), axis=0)\n",
    "                #\n",
    "                if last_item == leng:\n",
    "                    next_item = 0\n",
    "                else:\n",
    "                    next_item = last_item\n",
    "                #\n",
    "            #\n",
    "        #\n",
    "        return x, y\n",
    "    #\n",
    "    #\n",
    "#\n",
    "# Class that defines the model structure\n",
    "#\n",
    "class Model(nn.Module):\n",
    "    #\n",
    "    # Class defining network structure\n",
    "    #\n",
    "    def __init__(self):\n",
    "        #\n",
    "        # Start parent class\n",
    "        #\n",
    "        super(Model, self).__init__()\n",
    "        #\n",
    "        # This network is (input=4, ReLU=5, Softmax=5)\n",
    "        #\n",
    "        # Here we have the layers that have learned parameters\n",
    "        #\n",
    "        # NB: default for linear layer is bias=True\n",
    "        #\n",
    "        self.fc1 = nn.Linear(4, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        #\n",
    "    #\n",
    "    #\n",
    "    def forward(self, x):\n",
    "        #\n",
    "        # Here we have the sequence of operations. \n",
    "        #\n",
    "        # Note that Softmax is handled by cross entropy loss\n",
    "        #\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        #\n",
    "        return x\n",
    "    #\n",
    "#\n",
    "# Function to get validation loss\n",
    "#\n",
    "def validate(model, x_vali, y_vali):\n",
    "    #\n",
    "    # x_vali, y_vali = iris_loader.get_vali()\n",
    "    #\n",
    "    model.eval()\n",
    "    #\n",
    "    output = model(x_vali)  # only forward pass - NO gradients!!\n",
    "    #\n",
    "    loss = loss_function(output, y_vali)\n",
    "    #\n",
    "    return loss.data.item()\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a230053",
   "metadata": {},
   "source": [
    "### Model training ###\n",
    "\n",
    "Vary the optimizer (and other parameters) and see how this affects the training plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894dac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train the model\n",
    "# Instantiate model\n",
    "#\n",
    "model = Model()\n",
    "#\n",
    "# Define SGD optimizer\n",
    "#\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.4)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.4, momentum=0.9)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.4, momentum=0.9, nesterov=True)\n",
    "#\n",
    "# RMSprop optimizer\n",
    "#\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.04, alpha=0.99, eps=1e-08, weight_decay=0.1,\n",
    "                                momentum=0.5, centered=False)\n",
    "#\n",
    "#\n",
    "# Define Adam optimizer\n",
    "#\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999), eps=1e-08, weight_decay=0, lr=0.4)\n",
    "#\n",
    "# Define loss\n",
    "#\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "#\n",
    "# Instantiate data loader\n",
    "#\n",
    "iris_loader = IrisDataSet(\"./iris.csv\", 0.2, 0.2, int(96 / 2))\n",
    "#\n",
    "# Get a test set\n",
    "#\n",
    "#x_test, y_test = iris_loader.get_test()\n",
    "#\n",
    "# Get a validation set\n",
    "#\n",
    "#x_vali, y_vali = iris_loader.get_vali()\n",
    "#\n",
    "# Train function\n",
    "#\n",
    "def train(model, iris_loader, epoch, batches_in_epoch, report_batches):\n",
    "    #\n",
    "    # Train one epoch\n",
    "    #\n",
    "    model.train()\n",
    "    #\n",
    "    losses = []\n",
    "    #\n",
    "    for batch_number, (x, y) in enumerate(iris_loader):\n",
    "        #\n",
    "        if batch_number + 1 > batches_in_epoch:\n",
    "            break\n",
    "        #\n",
    "        # Copy data to GPU if available\n",
    "        #\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        #\n",
    "        optimizer.zero_grad() \n",
    "        #\n",
    "        output = model(x)\n",
    "        #\n",
    "        loss = loss_function(output, y)\n",
    "        #\n",
    "        loss.backward()\n",
    "        #\n",
    "        optimizer.step()\n",
    "        #\n",
    "        if batch_number % report_batches == 0:\n",
    "            #\n",
    "            # Comment in to see the detail\n",
    "            #\n",
    "            #print(\"Epoch\", epoch, \", batch_number\", batch_number, \", loss.data.item()\",\n",
    "            #     loss.data.item())\n",
    "            #\n",
    "            losses.append(loss.data.item())\n",
    "        #\n",
    "    #\n",
    "    return losses\n",
    "#\n",
    "# Do training\n",
    "#\n",
    "train_losses = []\n",
    "epoch_losses = []\n",
    "#\n",
    "for epoch in range(500):\n",
    "    #\n",
    "    this_epoch = train(model, iris_loader, epoch, batches_in_epoch=2, report_batches=10)\n",
    "    #\n",
    "    train_losses.append(this_epoch)\n",
    "    epoch_losses.append(this_epoch[-1])\n",
    "#\n",
    "# Plot loss function\n",
    "#\n",
    "plt.plot(epoch_losses, color=\"red\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
